# W2V Exercise
Keyword Embedding Model 

Keyword Embedding Technique takes as its input a large corpus of text and produces a high-dimensional space, with each unique word in the corpus being assigned a corresponding vector in the space.       
Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space           
Different View Points for the Same Corpus          
Example:            
```text
D1: 教練 評論 王建民 今日 投球 內容
D2: 教練 評論 郭泓志 今日 投球 表現
D3: 教練 談及 林書豪 今日 精彩 表現
```

## Objective

- Objective 1: 熟悉Linux環境, Command LINE Interface
- Objective 2: 了解從大量文字資料中找出知識(Knowledge)的可行性 (在這個例子中，是找到關鍵字同位詞的關係)           
